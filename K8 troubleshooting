Table of Contents

🔍 General Troubleshooting Strategy

🧱 Pod-Level Troubleshooting

⚙️ Deployment / ReplicaSet / StatefulSet

🧑‍💻 Node-Level Debugging

🌐 Networking Troubleshooting

📦 Storage & Volume Issues

🧩 Cluster & Control Plane Issues

🧰 Bonus: Useful Tools & Commands

= = = = = = = = = = = = = = = = = = = = = =
1.General Troubleshooting Strategy

Golden Rule:
Always troubleshoot from top → down, or symptom → root cause.

Check what’s wrong

kubectl get all -A


→ Gives a cluster-wide summary.

Find the namespace, pod, or deployment with issues

Describe the object

kubectl describe pod <pod-name> -n <namespace>


→ Look for Events, Warnings, ImagePullBackOff, CrashLoopBackOff, etc.

Check logs

kubectl logs <pod-name> -n <namespace> --tail=100
kubectl logs <pod-name> -n <namespace> -c <container-name>


If the pod has restarted multiple times:

kubectl get pod <pod-name> -n <namespace> -o wide
kubectl logs <pod-name> --previous

    
Check resource utilization

kubectl top pod -n <namespace>
kubectl top node

===========================================
2. Pod-Level Troubleshooting
🔹 Check Pod Status
kubectl get pods -A -o wide


Common statuses:

CrashLoopBackOff → app keeps crashing

ImagePullBackOff → image name/tag or credentials issue

Pending → not scheduled (node resource issue)

Evicted → node pressure (memory/disk)

🔹 Debugging a CrashLoopBackOff
kubectl logs <pod-name> --previous


→ Check what caused the last crash.

🔹 Debugging ImagePullBackOff
kubectl describe pod <pod-name>


→ Look for:

Wrong image name/tag

Missing imagePullSecrets

Private registry auth issues

🔹 Debugging Pending Pods
kubectl describe pod <pod-name>
kubectl get nodes


Look for:

“Insufficient CPU/memory”

Taints or node selectors mismatched

🔹 Run a temporary debug container
kubectl debug -it <pod-name> --image=busybox --target=<container-name> -- /bin/sh


=====================================

3. Deployment / ReplicaSet / StatefulSet Issues
🔹 Check rollout status
kubectl rollout status deployment/<deployment-name> -n <namespace>
kubectl rollout history deployment/<deployment-name>

🔹 Undo a failed deployment
kubectl rollout undo deployment/<deployment-name>

🔹 Check ReplicaSet
kubectl get rs -n <namespace>


→ Confirms whether replicas are being created.

🔹 Debug missing or misconfigured ConfigMaps / Secrets
kubectl describe pod <pod-name> | grep -i mount
kubectl get configmap <name> -n <namespace> -o yaml
kubectl get secret <name> -n <namespace> -o yaml
=============================================
4. Node-Level Debugging
🔹 Check node health
kubectl get nodes
kubectl describe node <node-name>


Common issues:

NotReady → kubelet or network down

DiskPressure / MemoryPressure → resource constraints

🔹 SSH into node
ssh <node-ip>
sudo journalctl -u kubelet

🔹 Check running containers
sudo crictl ps

🔹 Drain or cordon a problematic node
kubectl cordon <node-name>      # prevent new pods
kubectl drain <node-name> --ignore-daemonsets
=====================================

5. Networking Troubleshooting
🔹 Check service connectivity
kubectl get svc -n <namespace>
kubectl describe svc <service-name> -n <namespace>

🔹 Test from inside a pod

Run a debug pod:

kubectl run net-debug --image=busybox -it --rm -- sh


Inside the shell:

ping <service-name>
nslookup <service-name>
wget http://<service-name>:<port>

🔹 Check DNS
kubectl -n kube-system get pods -l k8s-app=kube-dns
kubectl logs -n kube-system <dns-pod-name>

🔹 Check NetworkPolicy
kubectl get networkpolicy -A


→ Ensure rules allow ingress/egress as expected.

🔹 Check CNI plugin (Calico, Flannel, etc.)
kubectl get pods -n kube-system | grep cni
kubectl logs <cni-pod> -n kube-system

= = = = = = = = = = = = = = = ========== = = = = = = = = = = = = = =

6. Storage & Volume Issues
🔹 Check PersistentVolumeClaims (PVCs)
kubectl get pvc -n <namespace>
kubectl describe pvc <pvc-name> -n <namespace>

🔹 Common errors

Pending → StorageClass not found or no PV available

MountVolume.SetUp failed → Node can’t attach volume

permission denied → wrong FS permissions

🔹 Check the node for mounted volumes
sudo lsblk
df -h

============ ============ ============== ===============

7. Cluster & Control Plane Troubleshooting
🔹 Check component status
kubectl get componentstatuses


(Deprecated in new versions; use metrics or kubelet healthz)

🔹 Inspect system pods
kubectl get pods -n kube-system
kubectl describe pod <name> -n kube-system
kubectl logs <pod> -n kube-system

🔹 Common checks:

kube-apiserver logs → auth/etcd issues

kube-controller-manager → pod scheduling failures

kube-scheduler → resource constraints

🔹 Check etcd health
ETCDCTL_API=3 etcdctl endpoint health

========= ============== ============= ============= =======

8. Bonus: Handy Tools & Shortcuts
Tool	Use
kubectl debug	Temporary container for debugging
kubectl cp	Copy files in/out of pods
stern / kubetail	Tail logs of multiple pods
k9s	TUI dashboard for interactive debugging
kubectx / kubens	Fast context and namespace switching
Lens IDE	GUI for cluster inspection
kubectl describe	Your best friend for event-based debugging

Practical Troubleshooting Flow (Summary)
1️⃣ kubectl get pods -A
2️⃣ kubectl describe pod <pod>
3️⃣ kubectl logs <pod>
4️⃣ kubectl get events --sort-by=.metadata.creationTimestamp
5️⃣ kubectl get nodes
6️⃣ kubectl describe node <node>
7️⃣ kubectl exec -it <pod> -- sh
8️⃣ kubectl top pods / nodes
9️⃣ Check services & endpoints
🔟 Inspect network policies & DNS

========= = =================== = =============== = ============


