Table of Contents

🔍 General Troubleshooting Strategy

🧱 Pod-Level Troubleshooting

⚙️ Deployment / ReplicaSet / StatefulSet

🧑‍💻 Node-Level Debugging

🌐 Networking Troubleshooting

📦 Storage & Volume Issues

🧩 Cluster & Control Plane Issues

🧰 Bonus: Useful Tools & Commands

= = = = = = = = = = = = = = = = = = = = = =
1.General Troubleshooting Strategy

Golden Rule:
Always troubleshoot from top → down, or symptom → root cause.

Check what’s wrong

kubectl get all -A


→ Gives a cluster-wide summary.

Find the namespace, pod, or deployment with issues

Describe the object

kubectl describe pod <pod-name> -n <namespace>


→ Look for Events, Warnings, ImagePullBackOff, CrashLoopBackOff, etc.

Check logs

kubectl logs <pod-name> -n <namespace> --tail=100
kubectl logs <pod-name> -n <namespace> -c <container-name>


If the pod has restarted multiple times:

kubectl get pod <pod-name> -n <namespace> -o wide
kubectl logs <pod-name> --previous

    
Check resource utilization

kubectl top pod -n <namespace>
kubectl top node

===========================================
2. Pod-Level Troubleshooting
🔹 Check Pod Status
kubectl get pods -A -o wide


Common statuses:

CrashLoopBackOff → app keeps crashing

ImagePullBackOff → image name/tag or credentials issue

Pending → not scheduled (node resource issue)

Evicted → node pressure (memory/disk)

🔹 Debugging a CrashLoopBackOff
kubectl logs <pod-name> --previous


→ Check what caused the last crash.

🔹 Debugging ImagePullBackOff
kubectl describe pod <pod-name>


→ Look for:

Wrong image name/tag

Missing imagePullSecrets

Private registry auth issues

🔹 Debugging Pending Pods
kubectl describe pod <pod-name>
kubectl get nodes


Look for:

“Insufficient CPU/memory”

Taints or node selectors mismatched

🔹 Run a temporary debug container
kubectl debug -it <pod-name> --image=busybox --target=<container-name> -- /bin/sh


=====================================

3. Deployment / ReplicaSet / StatefulSet Issues
🔹 Check rollout status
kubectl rollout status deployment/<deployment-name> -n <namespace>
kubectl rollout history deployment/<deployment-name>

🔹 Undo a failed deployment
kubectl rollout undo deployment/<deployment-name>

🔹 Check ReplicaSet
kubectl get rs -n <namespace>


→ Confirms whether replicas are being created.

🔹 Debug missing or misconfigured ConfigMaps / Secrets
kubectl describe pod <pod-name> | grep -i mount
kubectl get configmap <name> -n <namespace> -o yaml
kubectl get secret <name> -n <namespace> -o yaml
=============================================
4. Node-Level Debugging
🔹 Check node health
kubectl get nodes
kubectl describe node <node-name>


Common issues:

NotReady → kubelet or network down

DiskPressure / MemoryPressure → resource constraints

🔹 SSH into node
ssh <node-ip>
sudo journalctl -u kubelet

🔹 Check running containers
sudo crictl ps

🔹 Drain or cordon a problematic node
kubectl cordon <node-name>      # prevent new pods
kubectl drain <node-name> --ignore-daemonsets
=====================================

5. Networking Troubleshooting
🔹 Check service connectivity
kubectl get svc -n <namespace>
kubectl describe svc <service-name> -n <namespace>

🔹 Test from inside a pod

Run a debug pod:

kubectl run net-debug --image=busybox -it --rm -- sh


Inside the shell:

ping <service-name>
nslookup <service-name>
wget http://<service-name>:<port>

🔹 Check DNS
kubectl -n kube-system get pods -l k8s-app=kube-dns
kubectl logs -n kube-system <dns-pod-name>

🔹 Check NetworkPolicy
kubectl get networkpolicy -A


→ Ensure rules allow ingress/egress as expected.

🔹 Check CNI plugin (Calico, Flannel, etc.)
kubectl get pods -n kube-system | grep cni
kubectl logs <cni-pod> -n kube-system

= = = = = = = = = = = = = = = ========== = = = = = = = = = = = = = =
