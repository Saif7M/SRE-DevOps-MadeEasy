Table of Contents

ğŸ” General Troubleshooting Strategy

ğŸ§± Pod-Level Troubleshooting

âš™ï¸ Deployment / ReplicaSet / StatefulSet

ğŸ§‘â€ğŸ’» Node-Level Debugging

ğŸŒ Networking Troubleshooting

ğŸ“¦ Storage & Volume Issues

ğŸ§© Cluster & Control Plane Issues

ğŸ§° Bonus: Useful Tools & Commands

= = = = = = = = = = = = = = = = = = = = = =
1.General Troubleshooting Strategy

Golden Rule:
Always troubleshoot from top â†’ down, or symptom â†’ root cause.

Check whatâ€™s wrong

kubectl get all -A


â†’ Gives a cluster-wide summary.

Find the namespace, pod, or deployment with issues

Describe the object

kubectl describe pod <pod-name> -n <namespace>


â†’ Look for Events, Warnings, ImagePullBackOff, CrashLoopBackOff, etc.

Check logs

kubectl logs <pod-name> -n <namespace> --tail=100
kubectl logs <pod-name> -n <namespace> -c <container-name>


If the pod has restarted multiple times:

kubectl get pod <pod-name> -n <namespace> -o wide
kubectl logs <pod-name> --previous

    
Check resource utilization

kubectl top pod -n <namespace>
kubectl top node

===========================================
2. Pod-Level Troubleshooting
ğŸ”¹ Check Pod Status
kubectl get pods -A -o wide


Common statuses:

CrashLoopBackOff â†’ app keeps crashing

ImagePullBackOff â†’ image name/tag or credentials issue

Pending â†’ not scheduled (node resource issue)

Evicted â†’ node pressure (memory/disk)

ğŸ”¹ Debugging a CrashLoopBackOff
kubectl logs <pod-name> --previous


â†’ Check what caused the last crash.

ğŸ”¹ Debugging ImagePullBackOff
kubectl describe pod <pod-name>


â†’ Look for:

Wrong image name/tag

Missing imagePullSecrets

Private registry auth issues

ğŸ”¹ Debugging Pending Pods
kubectl describe pod <pod-name>
kubectl get nodes


Look for:

â€œInsufficient CPU/memoryâ€

Taints or node selectors mismatched

ğŸ”¹ Run a temporary debug container
kubectl debug -it <pod-name> --image=busybox --target=<container-name> -- /bin/sh


=====================================

3. Deployment / ReplicaSet / StatefulSet Issues
ğŸ”¹ Check rollout status
kubectl rollout status deployment/<deployment-name> -n <namespace>
kubectl rollout history deployment/<deployment-name>

ğŸ”¹ Undo a failed deployment
kubectl rollout undo deployment/<deployment-name>

ğŸ”¹ Check ReplicaSet
kubectl get rs -n <namespace>


â†’ Confirms whether replicas are being created.

ğŸ”¹ Debug missing or misconfigured ConfigMaps / Secrets
kubectl describe pod <pod-name> | grep -i mount
kubectl get configmap <name> -n <namespace> -o yaml
kubectl get secret <name> -n <namespace> -o yaml
=============================================
4. Node-Level Debugging
ğŸ”¹ Check node health
kubectl get nodes
kubectl describe node <node-name>


Common issues:

NotReady â†’ kubelet or network down

DiskPressure / MemoryPressure â†’ resource constraints

ğŸ”¹ SSH into node
ssh <node-ip>
sudo journalctl -u kubelet

ğŸ”¹ Check running containers
sudo crictl ps

ğŸ”¹ Drain or cordon a problematic node
kubectl cordon <node-name>      # prevent new pods
kubectl drain <node-name> --ignore-daemonsets
=====================================

5. Networking Troubleshooting
ğŸ”¹ Check service connectivity
kubectl get svc -n <namespace>
kubectl describe svc <service-name> -n <namespace>

ğŸ”¹ Test from inside a pod

Run a debug pod:

kubectl run net-debug --image=busybox -it --rm -- sh


Inside the shell:

ping <service-name>
nslookup <service-name>
wget http://<service-name>:<port>

ğŸ”¹ Check DNS
kubectl -n kube-system get pods -l k8s-app=kube-dns
kubectl logs -n kube-system <dns-pod-name>

ğŸ”¹ Check NetworkPolicy
kubectl get networkpolicy -A


â†’ Ensure rules allow ingress/egress as expected.

ğŸ”¹ Check CNI plugin (Calico, Flannel, etc.)
kubectl get pods -n kube-system | grep cni
kubectl logs <cni-pod> -n kube-system

= = = = = = = = = = = = = = = ========== = = = = = = = = = = = = = =
